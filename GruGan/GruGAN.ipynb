{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gru GAN 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100 # type=int, \"number of epochs of training\"\n",
    "batch_size = 1 # type=int, \"size of the batches\"\n",
    "\n",
    "lr = 0.002 # type=float \"adam: learning rate\"\n",
    "b1 = 0.9 # type=float \"adam: decay of first order momentum of gradient\"\n",
    "b2 = 0.999 # type=float \"adam: decay of first order momentum of gradient\"\n",
    "\n",
    "num_gpu = 2 \n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "latent_dim = 4 # type=int \"dimensionality of the latent space\"\n",
    "img_size = 1024 # type=int \"size of each image dimension\"\n",
    "channels = 1 # type=int \"number of image channels\"\n",
    "sample_interval = 10000 # int \"interval betwen image samples\"\n",
    "\n",
    "FLenTar = 100\n",
    "\n",
    "dataset_dir = r\"C:\\Users/Leo's PC/Documents/SSTP Tests/SSTP/GruGan/test_frames\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_dir, transform=None):\n",
    "\n",
    "        self.dir = file_dir\n",
    "        self.transform = transform\n",
    "        self.diction = {}\n",
    "        \n",
    "        idx = 0\n",
    "        for filename in os.listdir(self.dir):\n",
    "            if filename.endswith('jpg'):\n",
    "                self.diction[idx] = filename\n",
    "                idx += 1\n",
    "                        \n",
    "    def __len__(self):\n",
    "        return len(self.diction) - 1\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.diction[idx], self.diction[idx + 1]\n",
    "        directory_x, directory_y = self.dir + \"\\\\\" + str(x), self.dir + \"\\\\\" + str(y)\n",
    "        x, y = cv.imread(directory_x), cv.imread(directory_y)\n",
    "        if self.transform:\n",
    "            x, y = self.transform(x), self.transform(y)\n",
    "        return [x, y]\n",
    "\n",
    "    \n",
    "def HWC2CHW(x):\n",
    "    return np.array(x).transpose(2, 0, 1)\n",
    "\n",
    "\n",
    "dataset = Dataset(file_dir=dataset_dir, transform=HWC2CHW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #expected inout size (N, 3, 256, 128)\n",
    "        \n",
    "        #=======\n",
    "        #Encoder\n",
    "        #=======\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation1_1 = nn.ReLU()\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation1_2 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation2_1 = nn.ReLU()\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation2_2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation3_1 = nn.ReLU()\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=[3,3], stride=2, padding=1)\n",
    "        self.activation3_2 = nn.ReLU()\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation3_3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation4_1 = nn.ReLU()\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=2, padding=1)\n",
    "        self.activation4_2 = nn.ReLU()\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation4_3 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size = [2, 2], stride=2, padding=0)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation5_1 = nn.ReLU()      \n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=2, padding=1)\n",
    "        self.activation5_2 = nn.ReLU()\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation5_3 = nn.ReLU()\n",
    "        \n",
    "        #size = (N, 512, 4, 2)\n",
    "        \n",
    "        #=======\n",
    "        #Recurrent Module\n",
    "        #=======\n",
    "        \n",
    "        self.pool_r = nn.AdaptiveMaxPool2d(output_size = (2, 1))\n",
    "        \n",
    "        #size of GRU input = (batch_size, seq_len, inp_size)\n",
    "        self.gru = nn.GRU(input_size=1024, hidden_size=1024, num_layers=2, bias=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        self.upsample_r = nn.Upsample(size=(8, 4))\n",
    "        \n",
    "        #=======\n",
    "        #Decoder\n",
    "        #=======\n",
    "        \n",
    "        #size = (N, 512, 8, 4)\n",
    "        \n",
    "        self.conv6_1 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation6_1 = nn.ReLU()\n",
    "        self.conv6_2 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation6_2 = nn.ReLU()\n",
    "        self.conv6_3 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation6_3 = nn.ReLU()\n",
    "        self.upsample6 = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        self.conv7_1 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation7_1 = nn.ReLU()\n",
    "        self.conv7_2 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation7_2 = nn.ReLU()\n",
    "        self.conv7_3 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation7_3 = nn.ReLU()\n",
    "        self.upsample7 = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        self.conv8_1 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation8_1 = nn.ReLU()\n",
    "        self.conv8_2 = nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation8_2 = nn.ReLU()\n",
    "        self.conv8_3 = nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation8_3 = nn.ReLU()\n",
    "        self.upsample8 = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        self.conv9_1 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation9_1 = nn.ReLU()\n",
    "        self.conv9_2 = nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation9_2 = nn.ReLU()\n",
    "        self.upsample9 = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        self.conv10_1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation10_1 = nn.ReLU()\n",
    "        self.conv10_2 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=[3,3], stride=1, padding=1)\n",
    "        self.activation10_2 = nn.ReLU()\n",
    "        \n",
    "        self.output = nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=[1,1], stride=1, padding=0)\n",
    "        self.activation_output = nn.Sigmoid()\n",
    "        \n",
    "        self.h = torch.Tensor(np.random.randn(2, 2, 1024)) #(num_layers, batchsize, inp.shape)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        #=======\n",
    "        #Encoder\n",
    "        #=======\n",
    "        \n",
    "        x = self.conv1_1(x)\n",
    "        x = self.activation1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.activation1_2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2_1(x)\n",
    "        x = self.activation2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.activation2_2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3_1(x)\n",
    "        x = self.activation3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.activation3_2(x)\n",
    "        x = self.conv3_3(x)\n",
    "        x = self.activation3_3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.conv4_1(x)\n",
    "        x = self.activation4_1(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.activation4_2(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.activation4_3(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = self.conv5_1(x)\n",
    "        x = self.activation5_1(x)       \n",
    "        x = self.conv5_2(x)\n",
    "        x = self.activation5_2(x)\n",
    "        x = self.conv5_3(x)\n",
    "        x = self.activation5_3(x)\n",
    "        \n",
    "        #=======\n",
    "        #Recurrent Module\n",
    "        #=======\n",
    "        \n",
    "        \n",
    "        x = self.pool_r(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        \n",
    "        x, self.h = self.gru(x, self.h)\n",
    "        \n",
    "        x = x[:,-1]\n",
    "        x = torch.reshape(x, (x.shape[0], 512, 2, 1))\n",
    "        \n",
    "        x = self.upsample_r(x)\n",
    "        \n",
    "        #=======\n",
    "        #Decoder\n",
    "        #=======\n",
    "        \n",
    "        x = self.conv6_1(x)\n",
    "        x = self.activation6_1(x)\n",
    "        x = self.conv6_2(x)\n",
    "        x = self.activation6_2(x)\n",
    "        x = self.conv6_3(x)\n",
    "        x = self.activation6_3(x)\n",
    "        x = self.upsample6(x)\n",
    "        \n",
    "        x = self.conv7_1(x)\n",
    "        x = self.activation7_1(x)\n",
    "        x = self.conv7_2(x)\n",
    "        x = self.activation7_2(x)\n",
    "        x = self.conv7_3(x)\n",
    "        x = self.activation7_3(x)\n",
    "        x = self.upsample7(x)\n",
    "        \n",
    "        x = self.conv8_1(x)\n",
    "        x = self.activation8_1(x)\n",
    "        x = self.conv8_2(x)\n",
    "        x = self.activation8_2(x)\n",
    "        x = self.conv8_3(x)\n",
    "        x = self.activation8_3(x)\n",
    "        x = self.upsample8(x)\n",
    "        \n",
    "        x = self.conv9_1(x)\n",
    "        x = self.activation9_1(x)\n",
    "        x = self.upsample9(x)\n",
    "        x = self.conv9_2(x)\n",
    "        x = self.activation9_2(x)\n",
    "        x = self.upsample9(x)\n",
    "        \n",
    "        x = self.conv10_1(x)\n",
    "        x = self.activation10_1(x)\n",
    "        x = self.conv10_2(x)\n",
    "        x = self.activation10_2(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        x = self.activation_output(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def name(self):\n",
    "        return \"Generator\"\n",
    "    \n",
    "    \n",
    "    def load_SalGan_weights(self, pretrained_weights='gen_modelWeights0090.npz'):\n",
    "        \n",
    "        self.pretrained_weights = np.load(open(pretrained_weights, 'rb'), allow_pickle=True)\n",
    "        \n",
    "        self.layers = [module for module in self.modules() if type(module) != nn.Sequential]\n",
    "        self.conv_layers = [conv for conv in self.layers if type(conv) == nn.modules.conv.Conv2d or type(conv) == nn.modules.conv.ConvTranspose2d]\n",
    "\n",
    "        array_idx = 0\n",
    "        for layer in self.conv_layers:\n",
    "\n",
    "            if type(layer) == nn.modules.conv.ConvTranspose2d:\n",
    "                #the dim order of weight shape is messed up for ConvTranspose, so do transpose before loading\n",
    "\n",
    "                self.reshaped_array = self.pretrained_weights['arr_' + str(array_idx)].transpose(1, 0, 2, 3)\n",
    "\n",
    "                if layer.weight.shape == self.reshaped_array.shape:\n",
    "                    layer.weight = nn.Parameter(torch.from_numpy(self.reshaped_array).float())\n",
    "                else:\n",
    "                    print(\"One layer was initialized with Xavier due to shape mismatch\")\n",
    "                    torch.nn.init.xavier_uniform_(layer.weight)           \n",
    "                \n",
    "                array_idx += 1  #add 1 to idx to fetch the next element from the file\n",
    "\n",
    "                self.reshaped_array = self.pretrained_weights['arr_' + str(array_idx)]\n",
    "                \n",
    "                if layer.bias.shape == self.reshaped_array.shape:\n",
    "                    layer.bias = nn.Parameter(torch.from_numpy(self.reshaped_array.copy()).float())\n",
    "                else:\n",
    "                    layer.bias.data.fill_(0.01)\n",
    "\n",
    "            else: \n",
    "                layer.weight = nn.Parameter(torch.from_numpy(self.pretrained_weights['arr_' + str(array_idx)]).float())\n",
    "\n",
    "                array_idx += 1  #add 1 to idx to fetch the next element from the file\n",
    "\n",
    "                layer.bias = nn.Parameter(torch.from_numpy(self.pretrained_weights['arr_' + str(array_idx)]).float())\n",
    "\n",
    "            array_idx += 1 #add 1 to idx to fetch the next element from the file\n",
    "    \n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.ResNet = torchvision.models.densenet121(pretrained=True)\n",
    "        self.ResNet.fc = nn.Linear(in_features=1000, out_features=1000, bias=True)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=1000, hidden_size=512, num_layers=3, bias=True, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(512, 2, bias=True)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        \n",
    "        try:\n",
    "            self.h\n",
    "        except:\n",
    "            print(x.shape)\n",
    "            self.h = torch.Tensor(np.random.randn(3, x.shape[0], 512)).cuda() #(num_layers, batchsize, inp.shape)\n",
    "        '''\n",
    "        x = self.ResNet(x)\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x, self.h = self.gru(x, self.h)\n",
    "        x = x[:,-1]\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        '''\n",
    "        return Variable(Tensor([[0.3, 0.7]]))\n",
    "    \n",
    "    \n",
    "    def name(self):\n",
    "        return \"Discriminator\"\n",
    "    \n",
    "    \n",
    "    def clear_mem(self):\n",
    "        try:\n",
    "            nn.init.xavier_uniform_(self.h)    \n",
    "        except:\n",
    "            print(\"Memory clear failed: hidden state does not exist.\")\n",
    "    \n",
    "    \n",
    "class StyleGanGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StyleGanGenerator, self).__init__()\n",
    "        \n",
    "        self.ResNet = torchvision.models.densenet121(pretrained=True)\n",
    "        self.ResNet.fc = nn.Linear(in_features=1000, out_features=1000, bias=True)\n",
    "            \n",
    "        self.gru = nn.GRU(input_size=1000, hidden_size=512, num_layers=3, bias=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        with open('ffhq256.pkl', 'rb') as f:\n",
    "            self.StyleGan = pickle.load(f)['G_ema'].cuda() \n",
    "        \n",
    "    #@autocast()    \n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            self.h\n",
    "        except:\n",
    "            self.h = torch.Tensor(np.random.randn(3, x.shape[0], 512)).cuda() #(num_layers, batchsize, inp.shape)\n",
    "\n",
    "        ## ENCODER\n",
    "        x = self.ResNet(x)\n",
    "        \n",
    "        ## GRU\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x, self.h = self.gru(x, self.h)\n",
    "        x = torch.squeeze(x, 1)\n",
    "        \n",
    "        ## DECODER\n",
    "        # x = self.StyleGan(x, None)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def name(self):\n",
    "        return \"StyleGanGenerator\"\n",
    "    \n",
    "    \n",
    "    def clear_mem(self):\n",
    "        try:\n",
    "            nn.init.xavier_uniform_(self.h)    \n",
    "        except:\n",
    "            print(\"Memory clear failed: hidden state does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthScheduler():\n",
    "    def __init__(self, target_seq_len=100):\n",
    "        self.target_len_final = target_seq_len\n",
    "        self.current_seq_len_target = 2\n",
    "        self.total_call_count = 0\n",
    "        self.running_count = 0\n",
    "        self.trained_count = 0\n",
    "        self.loss_hist = np.array([])\n",
    "    \n",
    "    \n",
    "    def approve(self, loss, current_seq_len):\n",
    "        def return_true(update=True):\n",
    "            self.total_call_count += 1\n",
    "            self.running_count = 0\n",
    "            self.trained_count += 1\n",
    "            \n",
    "            self.loss_hist = np.append(self.loss_hist, loss)\n",
    "            \n",
    "            if update: adjust_target_len()\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        def return_false():\n",
    "            self.total_call_count += 1\n",
    "            self.running_count += 1\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        def simple_len_counter():\n",
    "            return True if self.running_count >= self.current_seq_len_target else False\n",
    "        \n",
    "        def adjust_target_len():\n",
    "            self.dy = np.diff(self.loss_hist)\n",
    "            \n",
    "            try:\n",
    "                self.running_dy = self.running_dy * 0.9 + self.dy[-1] * (1 - 0.9)\n",
    "            except:\n",
    "                self.running_dy = self.running_dy\n",
    "                \n",
    "            if self.running_dy > -0.00005:\n",
    "                self.current_seq_len_target += 1\n",
    "                print('training length changed to', self.current_seq_len_target)\n",
    "        \n",
    "        \n",
    "        if self.total_call_count < 200:\n",
    "            # for the first 200 inputs, always return True\n",
    "            return return_true(update=False)\n",
    "        else:\n",
    "            return return_true() if self.running_count >= self.current_seq_len_target else return_false()\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.total_call_count = 0\n",
    "        self.running_count = 0\n",
    "        self.trained_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Optimizer, Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "G = StyleGanGenerator()\n",
    "D = Discriminator()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "G.cuda().to(device)\n",
    "D.cuda().to(device)\n",
    "adversarial_loss.cuda()\n",
    "\n",
    "\n",
    "#G = torch.nn.DataParallel(G)\n",
    "#D = torch.nn.DataParallel(D)\n",
    "\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "scheduler = LengthScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3207fefba2f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \"\"\"\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \"\"\"\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \"\"\"\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \"\"\"\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-3207fefba2f1>\u001b[0m in \u001b[0;36minit_weights\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvTranspose2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "G.apply(init_weights)\n",
    "D.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The Generator takes an input frame x, outputs a fake frame y_hat. If we calculate the loss and back_prop now, we are training a Generator that can predict the next frame. If a sequence of mutiple fake frames is desired during inference, we then feed the Generator y_hat as the input and get the next frame. However, here's a problem: during training, the model only learns how to produce a fake frame based on a real frame. If we want to countinuously feed the model hundreds of  fake frames, the quality of the output will deteriorate quickly.\n",
    "\n",
    "Therefore, we train the model in a way that it's loss is judged based on the whole sequence, not just the next frame. In a sense, this trains the model in a setup that is closer to its use-case senerio. However, keep in mind that the video is still generated by passing in fake(t-1) to get fake(t), in a loop.\n",
    "\n",
    "We propose a length scheduler that automatically determines the length of the output sequence based on which the generator will be judged. The generator will start with learning how to predict the next frame. When it gets good at it, it will learn to generate 2 frames, untill the target value is hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1536, 1000]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-2d9038eb6901>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mad_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgt_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1536, 1000]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "y_hat_list = []\n",
    "y_list = []\n",
    "rating = 0\n",
    "loss = 1\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "for i, x in enumerate(loader):\n",
    "    \n",
    "    x, y = Variable(x[0].type(Tensor)).cuda().to(device), Variable(x[1].type(Tensor)).cuda().to(device)\n",
    "    \n",
    "    #with autocast():\n",
    "    y_hat = G(x)\n",
    "        \n",
    "    y_hat_list.append(y_hat.cpu().detach().numpy())\n",
    "    \n",
    "    ## Evaluation and backprop\n",
    "    \n",
    "    if scheduler.approve(loss, len(y_hat_list)): #returns True if it approves of evaluation\n",
    "        \n",
    "        ## ========================\n",
    "        ## Train the Generator\n",
    "        ## ========================\n",
    "        \n",
    "        D.clear_mem()\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            for fake in y_hat_list:    \n",
    "                fake = Variable(Tensor(fake)).cuda().to(device)\n",
    "                rating = D(fake)\n",
    "                print('hello')\n",
    "            \n",
    "        ad_loss = adversarial_loss(rating, Variable(Tensor([1.0, 0.0])).unsqueeze(0))\n",
    "        gt_loss = adversarial_loss(y_hat, Tensor(np.random.randn(1, 512)))\n",
    "\n",
    "        g_loss = 0.7 * ad_loss + 0.3 * gt_loss\n",
    "        \n",
    "        g_loss.backward(retain_graph=True)\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        y_hat_list = []\n",
    "        y_list = []\n",
    "        x_list = []\n",
    "        \n",
    "        G.clear_mem()\n",
    "        \n",
    "        ## ========================\n",
    "        ## Train the Discriminator\n",
    "        ## ========================\n",
    "        \n",
    "        D.clear_mem()\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            rating = D(x)\n",
    "            for y_hat in y_hat_list:           \n",
    "                rating = D(y_hat)\n",
    "            fake_loss = adversarial_loss(rating, Variable(Tensor([0.0, 1.0])).unsqueeze(0))\n",
    "        \n",
    "            D.clear_mem()\n",
    "            \n",
    "            rating = D(x)\n",
    "            for y in y_list:\n",
    "                rating = D(y)\n",
    "            real_loss = adversarial_loss(rating, Variable(Tensor([1.0, 0.0])).unsqueeze(0))\n",
    "\n",
    "            d_loss = 0.5 * real_loss + 0.5 * fake_loss\n",
    "        \n",
    "        #scaler.scale(d_loss).backward()\n",
    "        #scaler.step(optimizer_D) \n",
    "        #scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "checkpoint_file = open(r\"C:/Users/Leo's PC/Documents/SSTP Tests/Chinese Characters/LightGAN out/G.tar\", 'wb')\n",
    "torch.save({'model': G.state_dict()}, checkpoint_file)\n",
    "checkpoint_file.close()\n",
    "\n",
    "checkpoint = torch.load(open(\"C:/Users/Leo's PC/Documents/SSTP Tests/Chinese Characters/LightGAN out/G.tar\", 'rb'))\n",
    "G.load_state_dict(checkpoint['model'])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
