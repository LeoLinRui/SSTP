{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NYwcbGFSrZEE"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc, imread\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import warnings\n",
    "\n",
    "from ModelZoo import TemporalDiscriminator, StyleGanGenerator, StyleGanDiscriminator\n",
    "\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4N2qcsaZeX0u"
   },
   "outputs": [],
   "source": [
    "class PretrainModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PretrainModel, self).__init__()\n",
    "\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=[3, 3], stride=2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=[8, 8], stride=1, padding=0)\n",
    "        self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=[7, 7], stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=[7, 7], stride=2, padding=3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=[3, 3], stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=20000, kernel_size=[3, 3], stride=1, padding=1)\n",
    "\n",
    "        self.inter1 = nn.Conv2d(in_channels=20000, out_channels=64, kernel_size=[3, 3], stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inter2 = nn.Linear(64, 64)\n",
    "        self.bn5 = nn.BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inter3 = nn.ConvTranspose2d(in_channels=64, out_channels=128, kernel_size=[4, 4], padding=0)\n",
    "        self.bn6 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inter4 = nn.ConvTranspose2d(in_channels=128, out_channels=256, kernel_size=[4, 4], stride=2, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=[4, 4], stride=2, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=512, out_channels=128, kernel_size=[4, 4], stride=2, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=[4, 4], stride=2, padding=1)\n",
    "\n",
    "    \n",
    "    #@autocast()\n",
    "    def forward(self, x):\n",
    "        b = x.shape[0]\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        activation = x\n",
    "\n",
    "        ## Inter Layer. will be discarded in real use, for bottlenecking reason only.\n",
    "        x = self.inter1(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.inter2(x.view(b, 64))\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.inter3(x.view(b, 64, 1, 1))\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.inter4(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        ## Deconv Layers, will be finetuned with the reformer.\n",
    "        ## Has input shape of (b, 256, 1024) ==> all the embeddings for one image\n",
    "        ## first, reconstruct an image of size 16*16 from the embeddings, it will have 512 channels\n",
    "        x = x.view(b, 16, 16, 1024)\n",
    "        x = x.transpose(1, 3).transpose(2, 3)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.bn8(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.bn9(x)\n",
    "        x = self.deconv3(x)\n",
    "\n",
    "        return x, activation\n",
    "    \n",
    "    \n",
    "def one_diff_loss(inp): # output shape per pixel: inp = (b, 16, 16, 20000)\n",
    "\n",
    "    loss_function = nn.L1Loss()\n",
    "    inp = inp.reshape(inp.shape[0], inp.shape[1]*inp.shape[2], inp.shape[3]) # to shape (b, 256, 20000)\n",
    "    inp = F.softmax(inp, dim=2)\n",
    "    \n",
    "    print(torch.argmax(inp[0][0]), torch.max(inp[0][0]))\n",
    "    x = torch.argmax(inp, dim=2).unsqueeze(2) #index of shape (b, 256, 1)\n",
    "    \n",
    "    onehot = torch.zeros_like(inp) # (b, 256, 20000)\n",
    "    onehot.scatter_(dim=2, index=x, value=1, reduce='add')\n",
    "\n",
    "    return loss_function(inp, onehot)\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_dir, transform=None):\n",
    "\n",
    "        self.dir = file_dir\n",
    "        self.transform = transform\n",
    "        self.diction = {}\n",
    "        \n",
    "        idx = 0\n",
    "        for filename in os.listdir(self.dir):\n",
    "            if filename.endswith('jpg'):\n",
    "                self.diction[idx] = filename\n",
    "                idx += 1\n",
    "                        \n",
    "    def __len__(self):\n",
    "        return len(self.diction)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.diction[idx]\n",
    "        directory_x = self.dir + \"\\\\\" + str(x)\n",
    "        x = cv.imread(directory_x) / 255\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        x = torch.Tensor(x)\n",
    "        x = F.interpolate(x.unsqueeze(0), size=(128, 128)).squeeze(0)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def HWC2CHW(x):\n",
    "    return np.array(x).transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(file_dir=r\"C:\\Users\\Leo's PC\\Documents\\SSTP Tests\\SSTP\\Vformer\\test_frames\", transform=HWC2CHW)\n",
    "loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vformer_model import Conv, CombinedEmbedding, DeConv\n",
    "test_model = nn.Sequential(Conv(dic_size=16384),\n",
    "                           CombinedEmbedding(positional_encoding=False),\n",
    "                           DeConv(input_dim=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "jrBoYwtZhA0p",
    "outputId": "198085ee-2cac-46c4-9225-e1740aee8a56"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "MSE_loss = nn.L1Loss()\n",
    "L1_loss = nn.L1Loss().cuda()\n",
    "\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "model = test_model.cuda()\n",
    "# D = StyleGanDiscriminator()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.nn.DataParallel(model)\n",
    "# D = torch.nn.DataParallel(D)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.99))\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "training_log = {'iteration':[], 'loss':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 117, in forward\n    input = module(input)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"c:\\Users\\Leo's PC\\Documents\\SSTP Tests\\SSTP\\Vformer\\vformer_model.py\", line 82, in forward\n    out[i][j][k] = self.token_embedder(m)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 93, in forward\n    return F.linear(input, self.weight, self.bias)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\functional.py\", line 1692, in linear\n    output = input.matmul(weight.t())\nRuntimeError: both arguments to matmul need to be at least 1D, but they are 0D and 2D\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-188309796edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# print(torch.argmax(activation[0][0]), torch.max(activation[0][0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# have message field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 117, in forward\n    input = module(input)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"c:\\Users\\Leo's PC\\Documents\\SSTP Tests\\SSTP\\Vformer\\vformer_model.py\", line 82, in forward\n    out[i][j][k] = self.token_embedder(m)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 93, in forward\n    return F.linear(input, self.weight, self.bias)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\functional.py\", line 1692, in linear\n    output = input.matmul(weight.t())\nRuntimeError: both arguments to matmul need to be at least 1D, but they are 0D and 2D\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "for epoch in range(300):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, imgs in enumerate(loader):\n",
    "\n",
    "        imgs = Variable(imgs).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out, activation = model(imgs)\n",
    "        # print(torch.argmax(activation[0][0]), torch.max(activation[0][0]))\n",
    " \n",
    "        gt_loss = MSE_loss(out, imgs)\n",
    "        #ad_loss = MSE_loss(D(F.interpolate(out, size=(256, 256))), D(F.interpolate(imgs, size=(256, 256))).detach()*2)\n",
    "        ad_loss = L1_loss(D(F.interpolate(out, size=(256, 256))), torch.ones(BATCH_SIZE, 1).cuda()*0.3)\n",
    "        # print(gt_loss * 0.1, ad_loss * 0.5, one_diff_loss(activation) * 0.8)\n",
    "        loss = gt_loss * 0.2 + ad_loss * 0.3 + one_diff_loss(activation.transpose(1, 3)) * 0.5\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    print('Epoch {:d} | {:.2f} minutes | loss: {:.6f}'.format(epoch, (time.time() - start_time) / 60, total_loss/len(loader)))\n",
    "    \n",
    "    torchvision.utils.save_image(out[0], os.path.join(r\"C:/Users/Leo's PC/Documents/SSTP Tests/SSTP/Vformer/out_samples\", str(epoch) + '.jpg'))\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        with open(r\"C:/Users/Leo's PC/Documents/SSTP Tests/SSTP/Vformer/model_checkpoints/\" + str(epoch), 'wb') as checkpoint_file:\n",
    "            torch.save({'model': model.state_dict()}, checkpoint_file)\n",
    "        \n",
    "    training_log['iteration'].append(epoch)\n",
    "    training_log['loss'].append(total_loss/len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Caught AssertionError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 117, in forward\n    input = module(input)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"c:\\Users\\Leo's PC\\Documents\\SSTP Tests\\SSTP\\Vformer\\vformer_model.py\", line 54, in forward\n    assert torch.max(x) == 1 and torch.min(x) == 0, \"input has to be one-hot encoded. Got max {}, min {}\".format(torch.max(x), torch.min(x))\nAssertionError: input has to be one-hot encoded. Got max nan, min nan\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-58623a73d42c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# have message field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Caught AssertionError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 117, in forward\n    input = module(input)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pd\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"c:\\Users\\Leo's PC\\Documents\\SSTP Tests\\SSTP\\Vformer\\vformer_model.py\", line 54, in forward\n    assert torch.max(x) == 1 and torch.min(x) == 0, \"input has to be one-hot encoded. Got max {}, min {}\".format(torch.max(x), torch.min(x))\nAssertionError: input has to be one-hot encoded. Got max nan, min nan\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "for epoch in range(300):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, imgs in enumerate(loader):\n",
    "\n",
    "        imgs = Variable(imgs.half()).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            out = model(imgs)\n",
    "        print(out.dtype)\n",
    "        print(out.shape)\n",
    "        loss = MSE_loss(out, imgs)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    print('Epoch {:d} | {:.2f} minutes | loss: {:.6f}'.format(epoch, (time.time() - start_time) / 60, total_loss/len(loader)*BATCH_SIZE))\n",
    "    \n",
    "    torchvision.utils.save_image(out[0], os.path.join(r\"C:/Users/Leo's PC/Documents/SSTP Tests/SSTP/Vformer/out_samples\", str(epoch) + '.jpg'))\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        with open(r\"C:/Users/Leo's PC/Documents/SSTP Tests/SSTP/Vformer/model_checkpoints/\" + str(epoch), 'wb') as checkpoint_file:\n",
    "            torch.save({'model': model.state_dict()}, checkpoint_file)\n",
    "        \n",
    "    training_log['iteration'].append(epoch)\n",
    "    training_log['loss'].append(total_loss/len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXquSRKyMA6Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Visual Token Sample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}